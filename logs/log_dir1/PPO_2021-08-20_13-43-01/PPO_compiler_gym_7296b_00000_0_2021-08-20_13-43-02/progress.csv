episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,agent_timesteps_total,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,trial_id,hist_stats/episode_reward,hist_stats/episode_lengths,timers/sample_time_ms,timers/sample_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_agent_steps_sampled,info/num_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,info/learner/default_policy/learner_stats/allreduce_latency,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
nan,nan,nan,nan,0,7,70,70,False,0,1,fc15830ad7c34bc4adbff6a809ce27cc,2021-08-20_13-43-36,1629485016,9.906912803649902,9.906912803649902,32396,pootrick,192.168.0.74,9.906912803649902,0,1,7296b_00000,[],[],8257.322,8.477,1621.669,43.165,6.982,70,70,70,39.080000000000005,88.76,0.0,0.2,0.0001,-0.027462071739137173,-0.06692936969920993,0.03946605359669775,-2.9802322e-08,6.267175194807351e-06,4.820275187492371,0.0
